{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "import os.path "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step1: function for initiating the main dictionary of climate stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function: creating a dictionary for each climate station\n",
    "def create_dic(a):\n",
    "    a = {}\n",
    "    keys = ['fM', 'iPot', 'rSnow', 'dSnow', 'cPrec', 'dP', 'elev', 'lat', 'long', 'fileName']\n",
    "    a = {key: None for key in keys}\n",
    "    return a\n",
    "\n",
    "def initialize_input_dict (mainFolderSki):\n",
    "    # This function returns a dictionary , and addresses of 4 folders\n",
    "\n",
    "    ## Step 1:\n",
    "    rootFolder = mainFolderSki\n",
    "    inputFolder = os.path.join(rootFolder,'input')\n",
    "    ablationFolder = os.path.join(inputFolder, 'Ablation')\n",
    "    accumulationFolder = os.path.join(inputFolder, 'Accumulation')\n",
    "    climate_ref_Folder = os.path.join(inputFolder, 'Climate_ref')\n",
    "    \n",
    "    ## Step 2: Reading all files names inside the Ablation, Accumulation, and Climate folders \n",
    "    ablationFiles = []\n",
    "    for filename in os.walk(ablationFolder):\n",
    "        ablationFiles = filename[2]\n",
    "    \n",
    "    accumulationFiles = list()\n",
    "    for filename in os.walk(accumulationFolder):\n",
    "        accumulationFiles = filename[2]\n",
    "\n",
    "    climate_ref_Files = list()\n",
    "    for filename in os.walk(climate_ref_Folder):\n",
    "        climate_ref_Files = filename[2]\n",
    "        \n",
    "    ## Step 3: Reading files inside ablation folder\n",
    "    os.chdir(ablationFolder)\n",
    "    with open(ablationFiles[0], 'r') as file:\n",
    "        FM1 = file.read()\n",
    "    with open(ablationFiles[1], 'r') as file:\n",
    "        Ipot1 = file.read()\n",
    "    with open(ablationFiles[2], 'r') as file:\n",
    "        Rsnow1 = file.read()\n",
    "        \n",
    "    ## Step 4: Reading the lines of files inside ablation folder\n",
    "    FM1 = FM1.replace('\\n', '\\t')\n",
    "    FM1 = FM1.split('\\t')\n",
    "    Ipot1 = Ipot1.replace('\\n', '\\t').split('\\t')\n",
    "    Rsnow1 = Rsnow1.replace('\\n', '\\t').split('\\t')\n",
    "        \n",
    "    ## Step 5: Reading files inside accumulation folder\n",
    "    os.chdir(accumulationFolder)\n",
    "    \n",
    "    with open(accumulationFiles[0], 'r') as file:\n",
    "        cPrec = file.read()\n",
    "    with open(accumulationFiles[1], 'r') as file:\n",
    "        dSnow1 = file.read()\n",
    "    \n",
    "    cPrec = cPrec.replace('\\n', '\\t')\n",
    "    cPrec = cPrec.split('\\t')\n",
    "    dSnow1 = dSnow1.replace('\\n', '\\t').split('\\t')\n",
    "    \n",
    "    \n",
    "    ## Step 6: Reading the lines of files inside ablation folder\n",
    "    os.chdir(climate_ref_Folder)\n",
    "    \n",
    "    with open('pcp.txt', 'r') as file:\n",
    "        pcpData = file.read()\n",
    "    with open('tmp.txt', 'r') as file:\n",
    "        tmpData = file.read()\n",
    "        \n",
    "    pcpData = pcpData.split('\\n')\n",
    "    \n",
    "    for i in range(len(pcpData)):\n",
    "        pcpData[i] = pcpData[i].split(',')\n",
    "        \n",
    "    ## Step 7: Initialazing the input dictionary of climate stations which holds the information of accumulation a\n",
    "    ## and ablation, and etc of the stations\n",
    "    nameStn = []\n",
    "    for file in climate_ref_Files:\n",
    "        if 'p.csv' in file:\n",
    "            nameStn.append('n_' + file[-25: -5])\n",
    "\n",
    "    stnDicts = []\n",
    "    for i in range(len(nameStn)):\n",
    "        stnDicts.append(create_dic(nameStn[i]))\n",
    "    \n",
    "    ## Step 8: Assigning the file names to the dictionary\n",
    "    for i in range (len(nameStn)):\n",
    "        stnDicts[i]['fileName'] = nameStn[i]\n",
    "\n",
    "    \n",
    "    ## Step 9: Assigning the accumulation and ablation values\n",
    "    for stnDict in stnDicts:\n",
    "        for i, element in enumerate(FM1):\n",
    "            if element == stnDict['fileName'][2:]:\n",
    "                stnDict['fM'] = FM1[i+1]\n",
    "                \n",
    "        for i, element in enumerate(Ipot1):\n",
    "            if element == stnDict['fileName'][2:]:\n",
    "                stnDict['iPot'] = Ipot1[i+1]\n",
    "\n",
    "        for i, element in enumerate(Rsnow1):\n",
    "            if element == stnDict['fileName'][2:]:\n",
    "                stnDict['rSnow'] = Rsnow1[i+1]\n",
    "\n",
    "        for i, element in enumerate(dSnow1):\n",
    "            if element == stnDict['fileName'][2:]:\n",
    "                stnDict['dSnow'] = dSnow1[i+1]\n",
    "\n",
    "        for i, element in enumerate(cPrec):\n",
    "            stnDict['cPrec'] = cPrec[1]\n",
    "            stnDict['dP'] = cPrec[3]\n",
    "            \n",
    "    ## Step 10: Assigning the elevation, Lat and long to the dictionaries\n",
    "    for i in range(len(stnDicts)):\n",
    "        for j in range(len(pcpData)):\n",
    "            \n",
    "            if pcpData[j][1][2:-1] == stnDicts[i]['fileName'][2:]:\n",
    "            #if pcpData[j][1][:-1] == stnDicts[i]['fileName']:\n",
    "                stnDicts[i]['lat']= pcpData[j][2]\n",
    "                stnDicts[i]['long']= pcpData[j][3]\n",
    "                stnDicts[i]['elev']= pcpData[j][4]\n",
    "                \n",
    "    return stnDicts, inputFolder, ablationFolder, accumulationFolder, climate_ref_Folder;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step2: Initializiing the main dictionary for a case study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "atzmaeningStns = {}\n",
    "inputFolder = ''\n",
    "ablationFolder = ''\n",
    "accumulationFolder = ''\n",
    "climateFolder = ''\n",
    "root = 'C:/Users/ashrafse/SA_2/snowModelUZH/case2_Atzmaening'\n",
    "\n",
    "\n",
    "## calling the function with multiple return values\n",
    "atzmaeningStns, inputFolder, ablationFolder,  accumulationFolder, climateFolder = initialize_input_dict(root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step3: Match the station names in dictionary of stations with CSV files in Climate folder of case Study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcpAtzmaening = []\n",
    "tmpAtzmaening = []\n",
    "\n",
    "for i in range(len(atzmaeningStns)):\n",
    "    pcpAtzmaening.append(os.path.join(climateFolder, atzmaeningStns[i]['fileName'] + 'p.csv'))\n",
    "    tmpAtzmaening.append(os.path.join(climateFolder, atzmaeningStns[i]['fileName'] + 't.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:/Users/ashrafse/SA_2/snowModelUZH/case2_Atzmaening\\\\input\\\\Climate_ref\\\\n_47-2708333_9-0000000t.csv',\n",
       " 'C:/Users/ashrafse/SA_2/snowModelUZH/case2_Atzmaening\\\\input\\\\Climate_ref\\\\n_48-2708333_9-0208333t.csv',\n",
       " 'C:/Users/ashrafse/SA_2/snowModelUZH/case2_Atzmaening\\\\input\\\\Climate_ref\\\\n_49-2916667_9-0000000t.csv',\n",
       " 'C:/Users/ashrafse/SA_2/snowModelUZH/case2_Atzmaening\\\\input\\\\Climate_ref\\\\n_50-2916667_9-0208333t.csv']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmpAtzmaening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:/Users/ashrafse/SA_2/snowModelUZH/case2_Atzmaening\\\\input\\\\Climate_ref\\\\n_47-2708333_9-0000000p.csv',\n",
       " 'C:/Users/ashrafse/SA_2/snowModelUZH/case2_Atzmaening\\\\input\\\\Climate_ref\\\\n_48-2708333_9-0208333p.csv',\n",
       " 'C:/Users/ashrafse/SA_2/snowModelUZH/case2_Atzmaening\\\\input\\\\Climate_ref\\\\n_49-2916667_9-0000000p.csv',\n",
       " 'C:/Users/ashrafse/SA_2/snowModelUZH/case2_Atzmaening\\\\input\\\\Climate_ref\\\\n_50-2916667_9-0208333p.csv']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pcpAtzmaening"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step4: building database for each precipitation and temperature file in Climate folder and saving them in a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfpcp = [None for _ in range(len(pcpAtzmaening))]\n",
    "dftmp = [None for _ in range(len(tmpAtzmaening))]\n",
    "for i in range(len(pcpAtzmaening)):\n",
    "    dfpcp[i] = pd.read_csv(pcpAtzmaening[i])\n",
    "    dftmp[i] = pd.read_csv(tmpAtzmaening[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#type(dftmp[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#type(dftmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dftmp[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dftmp[0].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43465, 68)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfpcp[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns',69)\n",
    "pd.set_option('display.max_rows',138)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfpcp[0].head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dftmp[0].head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### making a header for output files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfpcpCol = dfpcp[0].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftmpCol = dftmp[0].columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### defining the length of simulations and scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenariosLength = len(dfpcpCol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scenariosLength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulationLength = len(dftmp[0][dftmpCol[0]]) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#simulationLength"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Main Snow Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(atzmaeningStns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dfpcp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Main Model\n",
    "\n",
    "\n",
    "\n",
    "## 1st column as index: makaing date from 01 01 1981 to 2099 12 31\n",
    "from datetime import timedelta, date\n",
    "\n",
    "def daterange(start_date, end_date):\n",
    "    for n in range(int ((end_date - start_date ).days + 1)):\n",
    "        yield start_date + timedelta(n)\n",
    "\n",
    "## Reading the beginning and end of the simulation\n",
    "start_date = date(1981, 1, 1)\n",
    "end_date = date(2099, 12, 31)\n",
    "dateList = []\n",
    "for single_date in daterange(start_date, end_date):\n",
    "    dateList.append(single_date.strftime(\"%m/%d/%Y\"))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Running the model for each climate station:\n",
    "for k in range(len(atzmaeningStns)):\n",
    "    \n",
    "    ## making a header for output files\n",
    "    dfpcpCol = dfpcp[k].columns\n",
    "    dftmpCol = dftmp[k].columns\n",
    "    \n",
    "    \n",
    "    ## defining the length of simulations and scenarios\n",
    "    scenariosLength = len(dfpcpCol)\n",
    "    simulationLength = len(dftmp[0][dftmpCol[0]]) - 1\n",
    "    \n",
    "    \n",
    "    ## declaring the initial arrays\n",
    "    accumulation = [0 for _ in range(simulationLength)]\n",
    "    ablation =  [0 for _ in range(simulationLength)]\n",
    "    snowDeposite = [0 for _ in range(simulationLength)]\n",
    "    total = np.zeros([simulationLength, 3*scenariosLength])\n",
    "    \n",
    "    \n",
    "    ## Running the model for each climate scenario:\n",
    "    for j in range(len(dfpcpCol)):\n",
    "        ## Reading the information and inputs of the first day of simulation\n",
    "        todayPCP = dfpcp[k][dfpcpCol[j]].iloc[1] if (dfpcp[k][dfpcpCol[j]].iloc[1] != -99) else 0\n",
    "        todayTMPMAX = round(dftmp[k][dftmpCol[2*j]].iloc[1],2) if(dftmp[k][dftmpCol[2*j]].iloc[1] != -99) else 0\n",
    "        todayTMPMIN = round(dftmp[k][dftmpCol[2*j+1]].iloc[1],2) if(dftmp[k][dftmpCol[2*j+1]].iloc[1] != -99) else 0\n",
    "        todayTMPAVE = round((todayTMPMAX+todayTMPMIN)/2,2) if((todayTMPMAX+todayTMPMIN)/2 != -99) else 0\n",
    "\n",
    "\n",
    "        ### Accumulation for the first day:\n",
    "        if (todayTMPAVE) <=-1:\n",
    "            accumulation[0] = todayPCP *(1 + float(atzmaeningStns[k]['cPrec']))*float(atzmaeningStns[k]['dSnow'])*(1)\n",
    "\n",
    "        elif -1 < (todayTMPAVE) <= 1:\n",
    "            accumulation[0] = todayPCP *(1 + float(atzmaeningStns[k]['cPrec']))*float(atzmaeningStns[k]['dSnow'])*float((1-todayTMPAVE)/2)\n",
    "\n",
    "        else: accumulation[0] = 0\n",
    "\n",
    "\n",
    "        ### Ablation for the first day:\n",
    "        if todayTMPAVE <= 1:\n",
    "             ablation[0] = 0\n",
    "        else: \n",
    "            ablation[0] = (float(atzmaeningStns[k]['fM']) + float(atzmaeningStns[k]['rSnow'])*float(atzmaeningStns[k]['iPot'])*0.01)*float(todayTMPAVE)*(1+0)\n",
    "\n",
    "        ### Main mass balance equation for the first day:\n",
    "        snowDeposite[0] = 0 if (0 + accumulation[0] - ablation[0]) < 0 else (0 + accumulation[0] - ablation[0])\n",
    "\n",
    "        ### storing three values in a list for the first day\n",
    "        total[0,3*j+0] = round((accumulation[0] - ablation[0]), 2)\n",
    "        total[0,3*j+1] = round(snowDeposite[0], 2)\n",
    "        total[0,3*j+2] = 1 if (total[0,3*j+1] > 300) else 0\n",
    "\n",
    "        \n",
    "        ## For the second day to the end of simulation:\n",
    "        i = 0\n",
    "        for i in range(2, simulationLength + 1, 1):\n",
    "            # precipitation and temperature missing values were handled\n",
    "\n",
    "            ## Reading the information and inputs of the first day of simulation\n",
    "            todayPCP = dfpcp[k][dfpcpCol[j]].iloc[i] if (dfpcp[k][dfpcpCol[j]].iloc[i] != -99) else 0\n",
    "            todayTMPMAX = round(dftmp[k][dftmpCol[2*j]].iloc[i],2) if(dftmp[k][dftmpCol[2*j]].iloc[i] != -99) else 0\n",
    "            todayTMPMIN = round(dftmp[k][dftmpCol[2*j+1]].iloc[i],2) if(dftmp[k][dftmpCol[2*j+1]].iloc[i] != -99) else 0\n",
    "            todayTMPAVE = round((todayTMPMAX+todayTMPMIN)/2,2) if((todayTMPMAX+todayTMPMIN)/2 != -99) else 0\n",
    "\n",
    "            ### Accumulation :\n",
    "            if(todayTMPAVE) <= -1:\n",
    "                ## dar haghighat accumulation hast\n",
    "                accumulation[i-1] = todayPCP *(1 + float(atzmaeningStns[k]['cPrec']))*float(atzmaeningStns[k]['dSnow'])*(1)\n",
    "\n",
    "            elif -1 < (todayTMPAVE) <= 1:\n",
    "                accumulation[i-1] = todayPCP *(1 + float(atzmaeningStns[k]['cPrec']))*float(atzmaeningStns[k]['dSnow'])*float((1-todayTMPAVE)/2)\n",
    "\n",
    "            else: accumulation[i-1] = 0\n",
    "\n",
    "            ### Ablation :\n",
    "            if todayTMPAVE <= 0:\n",
    "                ablation[i-1] = 0\n",
    "            else: \n",
    "                ablation[i-1] = (float(atzmaeningStns[k]['fM']) + float(atzmaeningStns[k]['rSnow'])*float(atzmaeningStns[k]['iPot'])*0.01)*float(todayTMPAVE)*(1+0)\n",
    "\n",
    "            ### Main mass balance equation for second day to the end of simulation:\n",
    "            snowDeposite[i-1] = 0 if (snowDeposite[i-2] + accumulation[i-1] - ablation[i-1]) < 0 else (snowDeposite[i-2] + accumulation[i-1] - ablation[i-1])\n",
    "\n",
    "\n",
    "            ### storing three values in a list \n",
    "            total[i-1,3*j+0] = round((accumulation[i-1] - ablation[i-1]) , 2)\n",
    "            total[i-1,3*j+1] = round(snowDeposite[i-1], 2)\n",
    "            total[i-1,3*j+2] = 1 if (total[i-1,3*j+1] > 300) else 0\n",
    "\n",
    "            \n",
    "    ### Saving the output of total list in a csv file in a specific path\n",
    "    \n",
    "    ## 1st row as the column names:\n",
    "    columnsDF = [] \n",
    "    for col in dfpcpCol:\n",
    "        columnsDF.append('SnowAmount_' + col)\n",
    "        columnsDF.append('TotalSnowAmount_' + col)\n",
    "        columnsDF.append('isOverSnow_' + col)\n",
    "    \n",
    "    \n",
    "    columnsDF0 = ['DATE']\n",
    "    dfnew0 = pd.DataFrame(dateList, columns = columnsDF0)\n",
    "    dfnew = pd.DataFrame(total, columns = columnsDF)\n",
    "    df1 = pd.concat([dfnew0, dfnew], axis=1, sort=False)\n",
    "\n",
    "    if os.path.isdir(os.path.join(root, 'Outputs_py')):\n",
    "        pass\n",
    "    else: os.mkdir(os.path.join(root, 'Outputs_py'))\n",
    "\n",
    "    outfolder =os.path.join(root, 'Outputs_py') \n",
    "    outfileName = 'Total_daily_' + atzmaeningStns[k]['fileName'] + '.csv'\n",
    "    outputFile = os.path.join(outfolder, outfileName )\n",
    "    df1.to_csv(outputFile, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
